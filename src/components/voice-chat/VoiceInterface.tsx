'use client';

import React, { useState, useEffect, useCallback } from 'react';
import { VoiceAIClient } from '@/lib/voice-ai-client';
import {
  VoiceConnectionState,
  VoiceSessionState,
  VoiceInteractionEvent,
  VoiceAIConfig
} from '@/lib/types/voice';

interface VoiceInterfaceProps {
  onConversationUpdate?: (conversation: ConversationMessage[]) => void;
  onPromptEvolution?: (evolution: PromptEvolution) => void;
}

interface ConversationMessage {
  id: string;
  type: 'user' | 'ai';
  text: string;
  timestamp: number;
  isTranscribing?: boolean;
}

interface PromptEvolution {
  original: string;
  improved: string;
  improvements: string[];
  score: number;
}

/**
 * èªéŸ³å°è©±ä»‹é¢çµ„ä»¶ - éšæ®µ1æ ¸å¿ƒUI
 */
export const VoiceInterface: React.FC<VoiceInterfaceProps> = ({
  onConversationUpdate,
  onPromptEvolution
}) => {
  const [voiceClient, setVoiceClient] = useState<VoiceAIClient | null>(null);
  const [connectionState, setConnectionState] = useState<VoiceConnectionState>(VoiceConnectionState.DISCONNECTED);
  const [sessionState, setSessionState] = useState<VoiceSessionState>(VoiceSessionState.IDLE);
  const [conversation, setConversation] = useState<ConversationMessage[]>([]);
  const [isInitializing, setIsInitializing] = useState(false);
  const [currentTranscript, setCurrentTranscript] = useState('');
  const [error, setError] = useState<string | null>(null);

  /**
   * åˆå§‹åŒ–èªéŸ³å®¢æˆ¶ç«¯
   */
  const initializeVoiceClient = useCallback(async () => {
    if (isInitializing || voiceClient?.isConnected) return;
    
    setIsInitializing(true);
    setError(null);
    
    try {
      const config: VoiceAIConfig = {
        apiKey: process.env.NEXT_PUBLIC_GOOGLE_AI_API_KEY || '',
        model: 'gemini-2.5-flash-preview-native-audio-dialog',
        voice: 'Leda',
        language: 'zh-TW',
        sampleRate: 24000
      };
      
      const client = new VoiceAIClient(config);
      
      // è¨­ç½®äº‹ä»¶ç›£è½å™¨
      client.on('connectionStateChange', setConnectionState);
      client.on('sessionStateChange', setSessionState);
      client.on('voiceInteraction', handleVoiceInteraction);
      client.on('sessionStatsUpdate', handleSessionStatsUpdate);
      
      await client.connect();
      setVoiceClient(client);
      
      // æ·»åŠ æ­¡è¿è¨Šæ¯
      addConversationMessage({
        id: Date.now().toString(),
        type: 'ai',
        text: 'ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ï¼Œæº–å‚™å¹«åŠ©ä½ å’Œå­©å­ä¸€èµ·å‰µä½œç²¾å½©çš„å½±ç‰‡ã€‚è®“æˆ‘å€‘é–‹å§‹å°è©±å§ï¼',
        timestamp: Date.now()
      });
      
    } catch (err) {
      const errorMessage = err instanceof Error ? err.message : 'é€£æ¥å¤±æ•—';
      setError(errorMessage);
      console.error('[VoiceInterface] åˆå§‹åŒ–å¤±æ•—:', err);
    } finally {
      setIsInitializing(false);
    }
  }, [isInitializing, voiceClient]);

  /**
   * è™•ç†èªéŸ³äº’å‹•äº‹ä»¶
   */
  const handleVoiceInteraction = useCallback((event: VoiceInteractionEvent) => {
    switch (event.type) {
      case 'user_speech_start':
        setCurrentTranscript('');
        addConversationMessage({
          id: `user-${Date.now()}`,
          type: 'user',
          text: '',
          timestamp: event.timestamp,
          isTranscribing: true
        });
        break;
        
      case 'user_speech_end':
        // æ›´æ–°æœ€å¾Œä¸€æ¢ç”¨æˆ¶è¨Šæ¯
        setConversation(prev => {
          const updated = [...prev];
          const lastUserIndex = updated.findLastIndex(msg => msg.type === 'user');
          if (lastUserIndex !== -1) {
            updated[lastUserIndex] = {
              ...updated[lastUserIndex],
              text: currentTranscript || '(éŒ„éŸ³å®Œæˆï¼Œç­‰å¾…è½‰éŒ„...)',
              isTranscribing: false
            };
          }
          return updated;
        });
        break;
        
      case 'ai_response_start':
        addConversationMessage({
          id: `ai-${Date.now()}`,
          type: 'ai',
          text: event.data?.text || event.data?.message || 'æ­£åœ¨æ€è€ƒ...',
          timestamp: event.timestamp
        });
        break;
        
      case 'error':
        setError(event.data?.error || 'ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤');
        break;
    }
  }, [currentTranscript]);

  /**
   * è™•ç†æœƒè©±çµ±è¨ˆæ›´æ–°
   */
  const handleSessionStatsUpdate = useCallback((stats: any) => {
    console.log('[VoiceInterface] æœƒè©±çµ±è¨ˆæ›´æ–°:', stats);
  }, []);

  /**
   * æ·»åŠ å°è©±è¨Šæ¯
   */
  const addConversationMessage = useCallback((message: ConversationMessage) => {
    setConversation(prev => {
      const updated = [...prev, message];
      onConversationUpdate?.(updated);
      return updated;
    });
  }, [onConversationUpdate]);

  /**
   * é–‹å§‹/åœæ­¢éŒ„éŸ³
   */
  const toggleRecording = useCallback(() => {
    if (!voiceClient?.isConnected) return;
    
    if (voiceClient.isRecording) {
      voiceClient.stopRecording();
    } else {
      voiceClient.startRecording();
    }
  }, [voiceClient]);

  /**
   * æ–·é–‹é€£æ¥
   */
  const disconnect = useCallback(() => {
    if (voiceClient) {
      voiceClient.disconnect();
      setVoiceClient(null);
    }
  }, [voiceClient]);

  /**
   * çµ„ä»¶æ¸…ç†
   */
  useEffect(() => {
    return () => {
      if (voiceClient) {
        voiceClient.disconnect();
      }
    };
  }, [voiceClient]);

  /**
   * å–å¾—é€£æ¥ç‹€æ…‹é¡¯ç¤ºæ–‡å­—
   */
  const getConnectionStatusText = () => {
    switch (connectionState) {
      case VoiceConnectionState.CONNECTING:
        return 'æ­£åœ¨é€£æ¥...';
      case VoiceConnectionState.CONNECTED:
        return 'å·²é€£æ¥';
      case VoiceConnectionState.RECONNECTING:
        return 'é‡æ–°é€£æ¥ä¸­...';
      case VoiceConnectionState.ERROR:
        return 'é€£æ¥éŒ¯èª¤';
      default:
        return 'æœªé€£æ¥';
    }
  };

  /**
   * å–å¾—æœƒè©±ç‹€æ…‹é¡¯ç¤ºæ–‡å­—
   */
  const getSessionStatusText = () => {
    switch (sessionState) {
      case VoiceSessionState.LISTENING:
        return 'æ­£åœ¨è†è½...';
      case VoiceSessionState.PROCESSING:
        return 'è™•ç†ä¸­...';
      case VoiceSessionState.SPEAKING:
        return 'AI å›æ‡‰ä¸­...';
      default:
        return 'æº–å‚™å°±ç·’';
    }
  };

  return (
    <div className="flex flex-col h-full bg-background">
      {/* é ‚éƒ¨ç‹€æ…‹åˆ— */}
      <div className="bg-white border-b p-4 flex justify-between items-center">
        <div className="flex items-center space-x-4">
          <div className="flex items-center space-x-2">
            <div className={`w-3 h-3 rounded-full ${
              connectionState === VoiceConnectionState.CONNECTED ? 'bg-success' :
              connectionState === VoiceConnectionState.CONNECTING || connectionState === VoiceConnectionState.RECONNECTING ? 'bg-secondary animate-pulse' :
              'bg-red-500'
            }`} />
            <span className="text-sm text-gray-600">{getConnectionStatusText()}</span>
          </div>
          
          {connectionState === VoiceConnectionState.CONNECTED && (
            <div className="text-sm text-gray-500">
              {getSessionStatusText()}
            </div>
          )}
        </div>
        
        <div className="flex items-center space-x-2">
          {voiceClient?.isConnected && (
            <button
              onClick={disconnect}
              className="text-sm text-red-500 hover:text-red-700 transition-colors"
            >
              æ–·é–‹é€£æ¥
            </button>
          )}
        </div>
      </div>

      {/* å°è©±å€åŸŸ */}
      <div className="flex-1 overflow-y-auto p-4 space-y-4">
        {conversation.map((message) => (
          <div
            key={message.id}
            className={`flex ${message.type === 'user' ? 'justify-end' : 'justify-start'}`}
          >
            <div className={`max-w-xs lg:max-w-md px-4 py-2 rounded-2xl ${
              message.type === 'user'
                ? 'bg-primary text-white'
                : 'bg-white border shadow-sm'
            }`}>
              {message.isTranscribing ? (
                <div className="flex items-center space-x-2">
                  <div className="animate-pulse text-sm">æ­£åœ¨éŒ„éŸ³...</div>
                  <div className="flex space-x-1">
                    <div className="w-1 h-4 bg-current animate-bounce" style={{ animationDelay: '0ms' }} />
                    <div className="w-1 h-4 bg-current animate-bounce" style={{ animationDelay: '150ms' }} />
                    <div className="w-1 h-4 bg-current animate-bounce" style={{ animationDelay: '300ms' }} />
                  </div>
                </div>
              ) : (
                <p className="text-sm whitespace-pre-wrap">{message.text}</p>
              )}
              <p className="text-xs opacity-70 mt-1">
                {new Date(message.timestamp).toLocaleTimeString('zh-TW', {
                  hour: '2-digit',
                  minute: '2-digit'
                })}
              </p>
            </div>
          </div>
        ))}
      </div>

      {/* éŒ¯èª¤é¡¯ç¤º */}
      {error && (
        <div className="bg-red-50 border border-red-200 text-red-700 p-4 mx-4 rounded-lg">
          <p className="text-sm font-medium">é€£æ¥éŒ¯èª¤</p>
          <p className="text-sm">{error}</p>
          <button
            onClick={() => setError(null)}
            className="text-sm underline mt-2"
          >
            é—œé–‰
          </button>
        </div>
      )}

      {/* èªéŸ³æ§åˆ¶å€åŸŸ */}
      <div className="bg-white border-t p-6">
        <div className="flex flex-col items-center space-y-4">
          {!voiceClient?.isConnected ? (
            <button
              onClick={initializeVoiceClient}
              disabled={isInitializing}
              className="btn-primary flex items-center space-x-2"
            >
              {isInitializing ? (
                <div className="w-5 h-5 border-2 border-white border-t-transparent rounded-full animate-spin" />
              ) : (
                <span>ğŸ¤</span>
              )}
              <span>{isInitializing ? 'é€£æ¥ä¸­...' : 'é–‹å§‹èªéŸ³å°è©±'}</span>
            </button>
          ) : (
            <>
              <button
                onClick={toggleRecording}
                className={`voice-button ${
                  sessionState === VoiceSessionState.LISTENING ? 'recording' : 'idle'
                }`}
              >
                <span className="text-white text-2xl">
                  {sessionState === VoiceSessionState.LISTENING ? 'ğŸ›‘' : 'ğŸ¤'}
                </span>
              </button>
              
              <p className="text-sm text-gray-600 text-center">
                {sessionState === VoiceSessionState.LISTENING
                  ? 'æŒ‰ä½éŒ„éŸ³éµèªªè©±ï¼Œæ”¾é–‹çµæŸ'
                  : 'é»æ“Šé–‹å§‹éŒ„éŸ³'
                }
              </p>
            </>
          )}
        </div>
      </div>
    </div>
  );
};

export type { VoiceInterfaceProps };